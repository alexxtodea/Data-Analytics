{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text cleaning\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "mt = pd.read_csv('balanced_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [While, thugs, are, brutalising, women, in, .,...\n",
      "1        [This, is, ridiculous, and, anybody, with, com...\n",
      "2        [You, do, n't, have, to, be, imprisoned, for, ...\n",
      "3                            [and, open, this, week, !, .]\n",
      "4        [lured, home, by, thrown, out, ., setup, to, d...\n",
      "                               ...                        \n",
      "47546    [You, are, accusing, the, victim, ., She, was,...\n",
      "47547    [This, is, the, shocking, situation, in, the, ...\n",
      "47548    [Let, 's, see, how, much, the, world, cares, a...\n",
      "47549    [Strange, how, 4, of, the, most, u, attractive...\n",
      "47550    [Oh, I, wished, he, would, have, grab, me, ., ...\n",
      "Name: text, Length: 47551, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = mt['text'].apply(word_tokenize)\n",
    "print(tokenized_text)\n",
    "print(type(tokenized_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
